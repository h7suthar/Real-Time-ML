{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework#2-1.2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NUDW_db2ax_z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split \n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Housing_datapath = \"/content/drive/MyDrive/DL-Data/Housing.csv\"\n",
        "housing = pd.DataFrame(pd.read_csv(Housing_datapath))\n",
        "x_var = ['area','bedrooms', 'bathrooms', 'stories','parking']\n",
        "y_var = ['price']\n",
        "input_layer = 5\n",
        "samples = housing.shape[0]"
      ],
      "metadata": {
        "id": "djXdVaxBbCES"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0) \n",
        "houseData_train, houseData_valid = train_test_split(housing, train_size = 0.8, test_size = 0.2, random_state = np.random.randint(1))"
      ],
      "metadata": {
        "id": "rQ4I2NG0Sgzu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data_train = houseData_train[x_var]\n",
        "y_data_train = houseData_train[y_var]\n",
        "x_data_valid = houseData_valid[x_var]\n",
        "y_data_valid = houseData_valid[y_var]\n",
        "\n",
        "x_train = torch.tensor(x_data_train.values, dtype = torch.float32)\n",
        "x_valid = torch.tensor(x_data_valid.values, dtype = torch.float32)\n",
        "y_train = torch.tensor(y_data_train.values, dtype = torch.float32)\n",
        "y_valid = torch.tensor(y_data_valid.values, dtype = torch.float32)\n",
        "\n",
        "x_ntrain = torch.nn.functional.normalize(x_train, dim = 0)\n",
        "x_nvalid = torch.nn.functional.normalize(x_valid, dim = 0)\n",
        "y_ntrain = torch.nn.functional.normalize(y_train, dim = 0)\n",
        "y_nvalid = torch.nn.functional.normalize(y_valid, dim = 0)\n"
      ],
      "metadata": {
        "id": "AbRjxl9ta78v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs,optimizer,model,loss_fn,x_train_data,x_valid_data,y_train_data,y_valid_data):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    x_p_train = model(x_train_data)\n",
        "    loss_train = loss_fn(x_p_train, y_train_data)\n",
        "    x_p_valid = model(x_valid_data)\n",
        "    loss_val = loss_fn(x_p_valid,y_valid_data)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch == 1 or epoch % 20 == 0:\n",
        "       print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
        "                  f\" Validation loss {loss_val.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "aIGx-ZGp8FBA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "nn12_model = nn.Sequential(OrderedDict([\n",
        "            ('hidden_linear_1', nn.Linear(input_layer,8)),\n",
        "            ('hidden_activation_1', nn.Tanh()),\n",
        "            ('hidden_linear_2', nn.Linear(8, 4)),\n",
        "            ('hidden_activation_2', nn.Tanh()),\n",
        "            ('output_linear', nn.Linear(4, 1))\n",
        "]))\n",
        "nn12_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUyznl7gFS8X",
        "outputId": "d8ac6134-1137-4e57-b0ed-c051f7d524ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (hidden_linear_1): Linear(in_features=5, out_features=8, bias=True)\n",
              "  (hidden_activation_1): Tanh()\n",
              "  (hidden_linear_2): Linear(in_features=8, out_features=4, bias=True)\n",
              "  (hidden_activation_2): Tanh()\n",
              "  (output_linear): Linear(in_features=4, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in nn12_model.named_parameters():\n",
        "    print(name, param.shape)\n",
        "\n",
        "nn12_model.output_linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaalTo83VEeo",
        "outputId": "eac3a92c-344c-4d96-c9c0-9f7fbbe44675"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_linear_1.weight torch.Size([8, 5])\n",
            "hidden_linear_1.bias torch.Size([8])\n",
            "hidden_linear_2.weight torch.Size([4, 8])\n",
            "hidden_linear_2.bias torch.Size([4])\n",
            "output_linear.weight torch.Size([1, 4])\n",
            "output_linear.bias torch.Size([1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.1113], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(nn12_model.parameters(), lr=1e-3) \n",
        "print(y_valid.dtype)\n",
        "training_loop(\n",
        "    n_epochs = 200, \n",
        "    optimizer = optimizer,\n",
        "    model = nn12_model,\n",
        "    loss_fn = nn.MSELoss(),\n",
        "    x_train_data = x_ntrain,\n",
        "    x_valid_data = x_nvalid, \n",
        "    y_train_data = y_ntrain,\n",
        "    y_valid_data = y_nvalid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiNmSr76VXOP",
        "outputId": "5792adf2-8caa-4a1c-93ae-5503e8b68935"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "Epoch 1, Training loss 0.0460, Validation loss 0.0687\n",
            "Epoch 20, Training loss 0.0414, Validation loss 0.0631\n",
            "Epoch 40, Training loss 0.0371, Validation loss 0.0578\n",
            "Epoch 60, Training loss 0.0332, Validation loss 0.0530\n",
            "Epoch 80, Training loss 0.0298, Validation loss 0.0486\n",
            "Epoch 100, Training loss 0.0267, Validation loss 0.0447\n",
            "Epoch 120, Training loss 0.0239, Validation loss 0.0411\n",
            "Epoch 140, Training loss 0.0215, Validation loss 0.0379\n",
            "Epoch 160, Training loss 0.0192, Validation loss 0.0350\n",
            "Epoch 180, Training loss 0.0173, Validation loss 0.0323\n",
            "Epoch 200, Training loss 0.0155, Validation loss 0.0299\n"
          ]
        }
      ]
    }
  ]
}