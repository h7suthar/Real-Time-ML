{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework#3-2-a.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g3OlbAduUoJA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import datetime  \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
        "data_path = '../data-unversioned/p1ch7/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sycXPue_Uv8X",
        "outputId": "6e1063f6-217b-487c-b4bf-d2b66395f531"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on device cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = datasets.CIFAR10(data_path, train=True, download= True)           # Training dataset....\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download= True)      # Dataset for validation...."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zauINItAUyLm",
        "outputId": "0579b8b8-0439-437b-ee47-0fb2dc442a0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'] # class definations..."
      ],
      "metadata": {
        "id": "e3KS36B4U4Gx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset into training and validation set...\n",
        "\n",
        "# Trainig data...\n",
        "transformed_cifar10_Train = datasets.CIFAR10(\n",
        "    data_path, train=True, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "# Validation data...\n",
        "transformed_cifar10_Val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "metadata": {
        "id": "a3CKEUYeU66e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class defining the ResBlock...\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, n_chans):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
        "                              padding=1, bias=False)  # <1>\n",
        "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
        "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
        "                                      nonlinearity='relu')  # <2>\n",
        "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
        "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.batch_norm(out)\n",
        "        out = torch.relu(out)\n",
        "        return out + x\n",
        "\n",
        "\n",
        "# Class \"ResNet-10\" for model defination with 10 ResBlocks...\n",
        "class ResNet10(nn.Module):\n",
        "    def __init__(self, n_chans1=32, n_blocks=10):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.resblocks = nn.Sequential(\n",
        "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = self.resblocks(out)\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Traing loop function...\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):  \n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  \n",
        "            imgs = imgs.to(device=device)  \n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)  \n",
        "            loss = loss_fn(outputs, labels)  \n",
        "            optimizer.zero_grad()         \n",
        "            loss.backward()         \n",
        "            optimizer.step()  \n",
        "            loss_train += loss.item()  \n",
        "\n",
        "        if epoch == 1 or epoch % 30 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader))) \n",
        "\n",
        "# Function calculating the validation of the model...\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad(): \n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)  \n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) \n",
        "                total += labels.shape[0]  \n",
        "                correct += int((predicted == labels).sum())  \n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))"
      ],
      "metadata": {
        "id": "o3XM-IQNU-sQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model \"ResNet-10\" with dataset divided into minibatches...\n",
        "train_mbload = torch.utils.data.DataLoader(transformed_cifar10_Train, batch_size=64, shuffle=True) \n",
        "\n",
        "model = ResNet10(n_chans1=32, n_blocks=10).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_mbload,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6ReQfTYVCPD",
        "outputId": "20a354ee-b5d2-4db7-9b92-17066047800b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-30 19:44:12.895694 Epoch 1, Training loss 1.6941019958242431\n",
            "2022-03-30 20:04:23.075390 Epoch 30, Training loss 0.5795664669912489\n",
            "2022-03-30 20:25:16.034818 Epoch 60, Training loss 0.3286413971687217\n",
            "2022-03-30 20:46:09.456711 Epoch 90, Training loss 0.16515082153289215\n",
            "2022-03-30 21:07:02.247998 Epoch 120, Training loss 0.08142360013402293\n",
            "2022-03-30 21:27:55.690763 Epoch 150, Training loss 0.02923778556061008\n",
            "2022-03-30 21:48:51.265012 Epoch 180, Training loss 0.005881584586624456\n",
            "2022-03-30 22:09:47.549380 Epoch 210, Training loss 0.0041174962627984315\n",
            "2022-03-30 22:30:43.822502 Epoch 240, Training loss 0.002355661442889052\n",
            "2022-03-30 22:51:42.783827 Epoch 270, Training loss 0.0028901498613949353\n",
            "2022-03-30 23:12:37.103490 Epoch 300, Training loss 0.002177377651135772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the accuracy of model...\n",
        "train_accuload = torch.utils.data.DataLoader(transformed_cifar10_Train, batch_size = 64, shuffle=False)\n",
        "Valid_accuload = torch.utils.data.DataLoader(transformed_cifar10_Val, batch_size = 64, shuffle=False)\n",
        "\n",
        "validate(model, train_accuload , Valid_accuload)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR1JmFAhVFTl",
        "outputId": "80ca9807-056e-4fc1-d7f1-f69f1514f898"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 1.00\n",
            "Accuracy val: 0.67\n"
          ]
        }
      ]
    }
  ]
}