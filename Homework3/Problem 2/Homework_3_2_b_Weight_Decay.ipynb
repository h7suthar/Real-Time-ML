{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jxPSTx2kv7W0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import datetime  \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
        "data_path = '../data-unversioned/p1ch7/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xYfTCbwwCSh",
        "outputId": "70eb0a83-e918-4236-d7b7-ca813ff17ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on device cuda.\n"
          ]
        }
      ],
      "source": [
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L9MYmjf2v6u",
        "outputId": "1b868370-4865-43f8-9cb5-c2451e7d0de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar10 = datasets.CIFAR10(data_path, train=True, download= True)           # Training dataset....\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download= True)      # Dataset for validation...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V481tukGwFkd"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'] # class definations..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cWKaHRrxwMoP"
      },
      "outputs": [],
      "source": [
        "# Splitting dataset into training and validation set...\n",
        "\n",
        "# Trainig data...\n",
        "transformed_cifar10_Train = datasets.CIFAR10(\n",
        "    data_path, train=True, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "# Validation data...\n",
        "transformed_cifar10_Val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X7_1_ExwwQEI"
      },
      "outputs": [],
      "source": [
        "# Class defining the ResBlock...\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, n_chans):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
        "                              padding=1, bias=False)  \n",
        "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
        "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
        "                                      nonlinearity='relu')  \n",
        "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
        "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.batch_norm(out)\n",
        "        out = torch.relu(out)\n",
        "        return out + x\n",
        "\n",
        "\n",
        "# Class \"ResNet-10\" for model defination with 10 ResBlocks...\n",
        "class ResNet10WD(nn.Module):\n",
        "    def __init__(self, n_chans1=32, n_blocks=10):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.resblocks = nn.Sequential(\n",
        "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = self.resblocks(out)\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Traing loop function...\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):  \n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  \n",
        "            imgs = imgs.to(device=device)  \n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)  \n",
        "            loss = loss_fn(outputs, labels)  \n",
        "            # Weight Decay part...\n",
        "            l2_lambda = 0.001\n",
        "            l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())  \n",
        "            loss = loss + l2_lambda * l2_norm\n",
        "            optimizer.zero_grad()         \n",
        "            loss.backward()         \n",
        "            optimizer.step()  \n",
        "            loss_train += loss.item()  \n",
        "\n",
        "        if epoch == 1 or epoch % 30 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader))) \n",
        "\n",
        "# Function calculating the validation of the model...\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad(): \n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)  \n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) \n",
        "                total += labels.shape[0]  \n",
        "                correct += int((predicted == labels).sum())  \n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWwTxeMswVeM",
        "outputId": "b3078fa8-4f24-44ff-9a31-33d5cd01547c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-31 00:42:53.097846 Epoch 1, Training loss 1.7589305970065123\n",
            "2022-03-31 01:04:16.940355 Epoch 30, Training loss 0.5936720286641279\n",
            "2022-03-31 01:26:26.255414 Epoch 60, Training loss 0.45230403233824484\n",
            "2022-03-31 01:48:37.320112 Epoch 90, Training loss 0.3880336124383275\n",
            "2022-03-31 02:10:43.716885 Epoch 120, Training loss 0.35624924364983274\n",
            "2022-03-31 02:32:49.794217 Epoch 150, Training loss 0.33727485938069157\n",
            "2022-03-31 02:54:57.875734 Epoch 180, Training loss 0.3516007904963725\n",
            "2022-03-31 03:17:03.774681 Epoch 210, Training loss 0.3419689454157334\n",
            "2022-03-31 03:39:09.809814 Epoch 240, Training loss 0.3181878054500236\n",
            "2022-03-31 04:01:13.473596 Epoch 270, Training loss 0.303562132408247\n",
            "2022-03-31 04:23:15.777618 Epoch 300, Training loss 0.31186046655220756\n"
          ]
        }
      ],
      "source": [
        "# Training the model \"ResNet-10\" with dataset divided into minibatches...\n",
        "train_mbload = torch.utils.data.DataLoader(transformed_cifar10_Train, batch_size=64, shuffle=True) \n",
        "\n",
        "model = ResNet10WD(n_chans1=32).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_mbload,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NHiL3zhAxD6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143bcd4e-6e23-4c8d-fcc4-05fd7c14ee27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.90\n",
            "Accuracy val: 0.66\n"
          ]
        }
      ],
      "source": [
        "# Checking the accuracy of model...\n",
        "train_accuload = torch.utils.data.DataLoader(transformed_cifar10_Train, batch_size = 64, shuffle=False)\n",
        "Valid_accuload = torch.utils.data.DataLoader(transformed_cifar10_Val, batch_size = 64, shuffle=False)\n",
        "\n",
        "validate(model, train_accuload , Valid_accuload)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Homework#3-2-b-Weight-Decay.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}