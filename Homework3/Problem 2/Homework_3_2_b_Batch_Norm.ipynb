{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework#3-2-b-Batch-Norm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qjCQWaOoJl3R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import datetime  \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
        "data_path = '../data-unversioned/p1ch7/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oU6sPl-KGf5",
        "outputId": "81665a6c-7409-4fb9-9d84-03c058e2605d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on device cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = datasets.CIFAR10(data_path, train=True, download= True)           # Training dataset....\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download= True)      # Dataset for validation...."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfSGQ_TMKI7P",
        "outputId": "83753649-fa2f-4cdd-b91b-02316d799ee6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'] # class definations..."
      ],
      "metadata": {
        "id": "jhUncUrVKLyN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset into training and validation set...\n",
        "\n",
        "# Trainig data...\n",
        "transformed_cifar10_Train = datasets.CIFAR10(\n",
        "    data_path, train=True, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "# Validation data...\n",
        "transformed_cifar10_Val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "metadata": {
        "id": "aBMfLsiGKOfp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class defining the ResBlock...\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, n_chans):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
        "                              padding=1, bias=False)  # <1>\n",
        "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
        "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
        "                                      nonlinearity='relu')  # <2>\n",
        "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
        "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.batch_norm(out)\n",
        "        out = torch.relu(out)\n",
        "        return out + x\n",
        "\n",
        "\n",
        "# Class \"ResNet-10\" for model defination with 10 ResBlocks...\n",
        "class ResNet10BN(nn.Module):\n",
        "    def __init__(self, n_chans1=32, n_blocks=10):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        # Batch Norm part...\n",
        "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
        "        self.resblocks = nn.Sequential(\n",
        "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Batch Norm part...\n",
        "        out = F.max_pool2d(torch.relu(self.conv1_batchnorm(self.conv1(x))), 2)\n",
        "        out = self.resblocks(out)\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Traing loop function...\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):  \n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  \n",
        "            imgs = imgs.to(device=device)  \n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)  \n",
        "            loss = loss_fn(outputs, labels)  \n",
        "            optimizer.zero_grad()         \n",
        "            loss.backward()         \n",
        "            optimizer.step()  \n",
        "            loss_train += loss.item()  \n",
        "\n",
        "        if epoch == 1 or epoch % 30 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader))) \n",
        "\n",
        "# Function calculating the validation of the model...\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad(): \n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)  \n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) \n",
        "                total += labels.shape[0]  \n",
        "                correct += int((predicted == labels).sum())  \n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))"
      ],
      "metadata": {
        "id": "1ISYoQiQKUHC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model \"ResNet-10\" with dataset divided into minibatches...\n",
        "train_mbload = torch.utils.data.DataLoader(transformed_cifar10_Train, batch_size=64, shuffle=True) \n",
        "\n",
        "model = ResNet10BN(n_chans1=32, n_blocks=10).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_mbload,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zaX_WjFKZVp",
        "outputId": "4a2446cf-f758-41f9-f6a7-ea8bb349ee8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-31 00:42:22.012548 Epoch 1, Training loss 1.7120192020445528\n",
            "2022-03-31 01:02:59.712020 Epoch 30, Training loss 0.610275738227093\n",
            "2022-03-31 01:24:02.345697 Epoch 60, Training loss 0.38638055659925846\n",
            "2022-03-31 01:45:00.784462 Epoch 90, Training loss 0.23001980790130014\n",
            "2022-03-31 02:06:00.324907 Epoch 120, Training loss 0.12215372643021442\n",
            "2022-03-31 02:26:58.429140 Epoch 150, Training loss 0.0696690642891828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the accuracy of model...\n",
        "train_accuload = torch.utils.data.DataLoader(transformed_cifar10_Train, batch_size = 64, shuffle=False)\n",
        "Valid_accuload = torch.utils.data.DataLoader(transformed_cifar10_Val, batch_size = 64, shuffle=False)\n",
        "\n",
        "validate(model, train_accuload , Valid_accuload)"
      ],
      "metadata": {
        "id": "qB3dQrGAKr_k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}